{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists('./csv_files'):\n",
    "    os.makedirs('./csv_files')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists('./csv_files/4_poses_data_pose.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file generated and saved at: ./csv_files/4_poses_data_pose.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for generating the dataset\n",
    "num_samples = 200   # Number of samples you want to generate\n",
    "num_features = 30   # Assuming 30 key points or features\n",
    "\n",
    "# Step 1: Generate random feature data\n",
    "# Using random numbers to simulate key points data, each row representing one yoga pose\n",
    "features = np.random.rand(num_samples, num_features)\n",
    "\n",
    "# Step 2: Generate pose labels (e.g., 4 classes of poses labeled as 0, 1, 2, 3)\n",
    "# Generating synthetic labels for the poses\n",
    "target = np.random.randint(0, 4, num_samples)\n",
    "\n",
    "# Step 3: Create a DataFrame with the generated data\n",
    "data_pose = pd.DataFrame(features, columns=[f'feature_{i}' for i in range(num_features)])\n",
    "data_pose['pose'] = target  # Adding the target label as 'pose'\n",
    "\n",
    "# Step 4: Save the generated data to the required CSV path\n",
    "csv_path = './csv_files/4_poses_data_pose.csv'\n",
    "data_pose.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"CSV file generated and saved at: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.67      0.44         6\n",
      "           1       0.00      0.00      0.00        12\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.33      0.23      0.27        13\n",
      "\n",
      "    accuracy                           0.17        40\n",
      "   macro avg       0.17      0.22      0.18        40\n",
      "weighted avg       0.16      0.17      0.16        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_pose = pd.read_csv(f\"./csv_files/{value}_poses_data_pose.csv\")\n",
    "features = data_pose.drop([\"pose\"], axis=1)\n",
    "target = data_pose[[\"pose\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2)\n",
    "\n",
    "data_all_pose_model = RandomForestClassifier()\n",
    "data_all_pose_model.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, data_all_pose_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pk.dump(data_all_pose_model, open(f\"./models/{value}_poses.model\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file generated and saved at: ./csv_files/4_angles_poses_angles.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for generating the angles dataset\n",
    "num_samples = 200  # Number of samples\n",
    "num_angles = 15    # Assume 15 key angles for each pose (e.g., shoulder, knee, elbow angles)\n",
    "\n",
    "# Step 1: Generate random angle data (values between 0 and 180 degrees)\n",
    "angles = np.random.uniform(low=0, high=180, size=(num_samples, num_angles))\n",
    "\n",
    "# Step 2: Generate target labels for poses (4 possible pose labels: 0, 1, 2, 3)\n",
    "# These labels represent the type of pose each row corresponds to\n",
    "pose_labels = np.random.randint(0, 4, num_samples)\n",
    "\n",
    "# Step 3: Create DataFrame with angles and pose labels\n",
    "angles_df = pd.DataFrame(angles, columns=[f'angle_{i}' for i in range(num_angles)])\n",
    "angles_df['pose'] = pose_labels\n",
    "\n",
    "# Step 4: Save the generated data to the required CSV path\n",
    "angles_csv_path = './csv_files/4_angles_poses_angles.csv'\n",
    "angles_df.to_csv(angles_csv_path, index=False)\n",
    "\n",
    "print(f\"CSV file generated and saved at: {angles_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from calc_angles import rangles\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Define column names for the pose landmarks CSV (each landmark has x, y, z, visibility)\n",
    "landmark_columns = [\n",
    "    f'{name}_{dim}' for name in [\n",
    "        'nose', 'left_eye_inner', 'left_eye', 'left_eye_outer',\n",
    "        'right_eye_inner', 'right_eye', 'right_eye_outer', 'left_ear', 'right_ear',\n",
    "        'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n",
    "        'left_wrist', 'right_wrist', 'left_pinky', 'right_pinky', 'left_index', 'right_index',\n",
    "        'left_thumb', 'right_thumb', 'left_hip', 'right_hip', 'left_knee', 'right_knee',\n",
    "        'left_ankle', 'right_ankle', 'left_heel', 'right_heel', 'left_foot_index', 'right_foot_index'\n",
    "    ] for dim in ['x', 'y', 'z', 'v']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1732205087.251968    9033 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1732205087.311528    9033 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1732205087.355151    9034 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "124 columns passed, passed data had 132 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/v2/yoga/yoga_env/lib/python3.12/site-packages/pandas/core/internals/construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/v2/yoga/yoga_env/lib/python3.12/site-packages/pandas/core/internals/construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    989\u001b[0m     )\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 124 columns passed, passed data had 132 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Create DataFrame from landmarks list\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m pose_landmarks_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlandmarks_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlandmark_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[1;32m     38\u001b[0m pose_landmarks_csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./csv_files/4_poses_data_pose.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/v2/yoga/yoga_env/lib/python3.12/site-packages/pandas/core/frame.py:851\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    860\u001b[0m         arrays,\n\u001b[1;32m    861\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    865\u001b[0m     )\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/v2/yoga/yoga_env/lib/python3.12/site-packages/pandas/core/internals/construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/v2/yoga/yoga_env/lib/python3.12/site-packages/pandas/core/internals/construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/v2/yoga/yoga_env/lib/python3.12/site-packages/pandas/core/internals/construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 124 columns passed, passed data had 132 columns"
     ]
    }
   ],
   "source": [
    "# List to store landmarks data for each frame\n",
    "landmarks_list = []\n",
    "\n",
    "# Set up video capture (use an existing video file)\n",
    "video_path = \"/home/ubuntu/v2/yoga/sy-1.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Set up MediaPipe Pose\n",
    "with mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the image color from BGR to RGB as MediaPipe uses RGB\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        # Check if pose landmarks are detected\n",
    "        if results.pose_landmarks:\n",
    "            # Extract the landmark data\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            frame_landmarks = []\n",
    "\n",
    "            # Extract x, y, z, visibility for each landmark\n",
    "            for landmark in landmarks:\n",
    "                frame_landmarks.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "\n",
    "            landmarks_list.append(frame_landmarks)\n",
    "\n",
    "# Release the video capture\n",
    "cap.release()\n",
    "\n",
    "# Create DataFrame from landmarks list\n",
    "pose_landmarks_df = pd.DataFrame(landmarks_list, columns=landmark_columns)\n",
    "\n",
    "# Save to CSV\n",
    "pose_landmarks_csv_path = \"./csv_files/4_poses_data_pose.csv\"\n",
    "os.makedirs('./csv_files', exist_ok=True)\n",
    "pose_landmarks_df.to_csv(pose_landmarks_csv_path, index=False)\n",
    "\n",
    "print(f\"Pose landmarks CSV file generated and saved at: {pose_landmarks_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns defined in landmark_columns: 124\n"
     ]
    }
   ],
   "source": [
    "# Define column names for the pose landmarks DataFrame correctly\n",
    "landmark_columns = [\n",
    "    f'{name}_{dim}' for name in [\n",
    "        'nose', 'left_eye_inner', 'left_eye', 'left_eye_outer',\n",
    "        'right_eye_inner', 'right_eye', 'right_eye_outer', \n",
    "        'left_ear', 'right_ear', 'left_shoulder', 'right_shoulder', \n",
    "        'left_elbow', 'right_elbow', 'left_wrist', 'right_wrist', \n",
    "        'left_pinky', 'right_pinky', 'left_index', 'right_index',\n",
    "        'left_thumb', 'right_thumb', 'left_hip', 'right_hip', \n",
    "        'left_knee', 'right_knee', 'left_ankle', 'right_ankle', \n",
    "        'left_heel', 'right_heel', 'left_foot_index', 'right_foot_index'\n",
    "    ] for dim in ['x', 'y', 'z', 'v']\n",
    "]\n",
    "\n",
    "# The above list should produce exactly 132 columns (33 landmarks * 4 dimensions)\n",
    "print(f\"Number of columns defined in landmark_columns: {len(landmark_columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns defined in landmark_columns: 132\n"
     ]
    }
   ],
   "source": [
    "# Define the correct column names for the pose landmarks DataFrame\n",
    "landmark_columns = [\n",
    "    f'{name}_{dim}' for name in [\n",
    "        'nose', 'left_eye_inner', 'left_eye', 'left_eye_outer',\n",
    "        'right_eye_inner', 'right_eye', 'right_eye_outer', \n",
    "        'left_ear', 'right_ear', 'mouth_left', 'mouth_right',\n",
    "        'left_shoulder', 'right_shoulder', \n",
    "        'left_elbow', 'right_elbow',\n",
    "        'left_wrist', 'right_wrist', \n",
    "        'left_pinky', 'right_pinky', \n",
    "        'left_index', 'right_index',\n",
    "        'left_thumb', 'right_thumb', \n",
    "        'left_hip', 'right_hip', \n",
    "        'left_knee', 'right_knee', \n",
    "        'left_ankle', 'right_ankle', \n",
    "        'left_heel', 'right_heel', \n",
    "        'left_foot_index', 'right_foot_index'\n",
    "    ] for dim in ['x', 'y', 'z', 'v']\n",
    "]\n",
    "\n",
    "# The above list should produce exactly 132 columns (33 landmarks * 4 dimensions)\n",
    "print(f\"Number of columns defined in landmark_columns: {len(landmark_columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pose landmarks CSV file generated and saved at: ./csv_files/4_poses_data_pose.csv\n"
     ]
    }
   ],
   "source": [
    "# Assuming you've already extracted landmarks and appended to landmarks_list\n",
    "# Create DataFrame from landmarks list with the correct number of columns\n",
    "pose_landmarks_df = pd.DataFrame(landmarks_list, columns=landmark_columns)\n",
    "\n",
    "# Save to CSV\n",
    "pose_landmarks_csv_path = \"./csv_files/4_poses_data_pose.csv\"\n",
    "os.makedirs('./csv_files', exist_ok=True)\n",
    "pose_landmarks_df.to_csv(pose_landmarks_csv_path, index=False)\n",
    "\n",
    "print(f\"Pose landmarks CSV file generated and saved at: {pose_landmarks_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from calc_angles import rangles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously generated landmarks CSV\n",
    "pose_landmarks_csv_path = \"./csv_files/4_poses_data_pose.csv\"\n",
    "pose_landmarks_df = pd.read_csv(pose_landmarks_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'left_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/v2/yoga/yoga_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'left_x'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Iterate over each row in the pose landmarks DataFrame to calculate angles\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m pose_landmarks_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Creating a dictionary for landmark points (x, y, z coordinates)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     landmarks_points \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 8\u001b[0m         landmark_name: [\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlandmark_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_x\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, row[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlandmark_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_y\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlandmark_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_z\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m landmark_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(col\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m pose_landmarks_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_x\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col)\n\u001b[1;32m     10\u001b[0m     }\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Calculate the angles using the rangles function from calc_angles.py\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     angles \u001b[38;5;241m=\u001b[39m rangles(pose_landmarks_df, landmarks_points)\n",
      "File \u001b[0;32m~/v2/yoga/yoga_env/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/v2/yoga/yoga_env/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/v2/yoga/yoga_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'left_x'"
     ]
    }
   ],
   "source": [
    "# List to store calculated angles for each sample/frame\n",
    "angles_list = []\n",
    "\n",
    "# Iterate over each row in the pose landmarks DataFrame to calculate angles\n",
    "for _, row in pose_landmarks_df.iterrows():\n",
    "    # Creating a dictionary for landmark points (x, y, z coordinates)\n",
    "    landmarks_points = {\n",
    "        landmark_name: [row[f\"{landmark_name}_x\"], row[f\"{landmark_name}_y\"], row[f\"{landmark_name}_z\"]]\n",
    "        for landmark_name in set(col.split('_')[0] for col in pose_landmarks_df.columns if '_x' in col)\n",
    "    }\n",
    "\n",
    "    # Calculate the angles using the rangles function from calc_angles.py\n",
    "    angles = rangles(pose_landmarks_df, landmarks_points)\n",
    "    angles_list.append(angles)\n",
    "\n",
    "# Step 4: Create a DataFrame for the calculated angles\n",
    "# Define the columns for angles based on what `rangles()` returns\n",
    "angle_columns = [\n",
    "    \"armpit_left\", \"armpit_right\", \"elbow_left\", \"elbow_right\",\n",
    "    \"hip_left\", \"hip_right\", \"knee_left\", \"knee_right\",\n",
    "    \"ankle_left\", \"ankle_right\"\n",
    "]\n",
    "\n",
    "angles_df = pd.DataFrame(angles_list, columns=angle_columns)\n",
    "\n",
    "# Step 5: Save the calculated angles to a CSV file\n",
    "angles_csv_path = \"./csv_files/4_angles_poses_angles.csv\"\n",
    "angles_df.to_csv(angles_csv_path, index=False)\n",
    "\n",
    "print(f\"Angles CSV file generated and saved at: {angles_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angles CSV file generated and saved at: ./csv_files/4_angles_poses_angles.csv\n"
     ]
    }
   ],
   "source": [
    "# List to store calculated angles for each sample/frame\n",
    "angles_list = []\n",
    "\n",
    "# List of all landmarks as defined in the original extraction\n",
    "landmark_names = [\n",
    "    'nose', 'left_eye_inner', 'left_eye', 'left_eye_outer',\n",
    "    'right_eye_inner', 'right_eye', 'right_eye_outer', \n",
    "    'left_ear', 'right_ear', 'mouth_left', 'mouth_right',\n",
    "    'left_shoulder', 'right_shoulder', \n",
    "    'left_elbow', 'right_elbow',\n",
    "    'left_wrist', 'right_wrist', \n",
    "    'left_pinky', 'right_pinky', \n",
    "    'left_index', 'right_index',\n",
    "    'left_thumb', 'right_thumb', \n",
    "    'left_hip', 'right_hip', \n",
    "    'left_knee', 'right_knee', \n",
    "    'left_ankle', 'right_ankle', \n",
    "    'left_heel', 'right_heel', \n",
    "    'left_foot_index', 'right_foot_index'\n",
    "]\n",
    "\n",
    "# Iterate over each row in the pose landmarks DataFrame to calculate angles\n",
    "for _, row in pose_landmarks_df.iterrows():\n",
    "    landmarks_points = {}\n",
    "\n",
    "    # Extract x, y, z for each landmark using the correct landmark names\n",
    "    for landmark_name in landmark_names:\n",
    "        try:\n",
    "            landmarks_points[landmark_name] = [\n",
    "                row[f\"{landmark_name}_x\"], \n",
    "                row[f\"{landmark_name}_y\"], \n",
    "                row[f\"{landmark_name}_z\"]\n",
    "            ]\n",
    "        except KeyError:\n",
    "            # Print warning if any landmark is missing\n",
    "            print(f\"Warning: Missing data for landmark {landmark_name}\")\n",
    "            continue\n",
    "\n",
    "    # Calculate the angles using the rangles function from calc_angles.py\n",
    "    angles = rangles(pose_landmarks_df, landmarks_points)\n",
    "    angles_list.append(angles)\n",
    "\n",
    "# Step 4: Create a DataFrame for the calculated angles\n",
    "# Define the columns for angles based on what `rangles()` returns\n",
    "angle_columns = [\n",
    "    \"armpit_left\", \"armpit_right\", \"elbow_left\", \"elbow_right\",\n",
    "    \"hip_left\", \"hip_right\", \"knee_left\", \"knee_right\",\n",
    "    \"ankle_left\", \"ankle_right\"\n",
    "]\n",
    "\n",
    "# Create DataFrame for the calculated angles\n",
    "angles_df = pd.DataFrame(angles_list, columns=angle_columns)\n",
    "\n",
    "# Step 5: Save the calculated angles to a CSV file\n",
    "angles_csv_path = \"./csv_files/4_angles_poses_angles.csv\"\n",
    "angles_df.to_csv(angles_csv_path, index=False)\n",
    "\n",
    "print(f\"Angles CSV file generated and saved at: {angles_csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
